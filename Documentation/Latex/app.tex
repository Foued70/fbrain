\section{Applications}

\subsection{Denoising \cite{coupe_2008}}

\begin{description}
 \item[btkNLMDenoising] This program applies a non-local mean filter to a 3D
image  for denoising purpose. Usage: \texttt{-i input\_image\_filename -o
output\_image\_filename}. The best results are usually obtained by using a mask
(or a padding value). This is an implementation of the method proposed by Coup\'e \textit{et al.} in \cite{coupe_2008}.
\end{description}

\begin{description}
 \item[btkNLMDenoising4DImage] This program applies a non-local mean filter to 
 each 3D image of a 4D image, for denoising purpose. Usage: \texttt{-i
input\_image\_filename -o output\_image\_filename}. The best results are usually
obtained by using a mask (or a padding value).
\end{description}


\subsection{Anatomical reconstruction}
\label{subsec:ana_rec}

\begin{description}
 \item[btkImageReconstruction] This program allows to obtain a
high-resolution image from a set of low-resolution images, typically
axial, coronal, and sagittal acquisitions~(similar to \cite{rousseau_registration_2006}). \\\\
Minimal usage: \texttt{btkImageReconstruction -i image1 $\cdots$ -i imageN -o
output --box}. 

Recommended usage: \texttt{btkImageReconstruction -i image1 $\cdots$ -i imageN
-m mask1 $\cdots$ -m maskN -o output --mask}. The use of a mask provide
better results since it allows an accuratelly estimation of the initial
transform, and constrains the registration to the region of interest.

The full list of optional parameters of the method can be obtained by
\texttt{btkImageReconstruction --help}

\end{description}

\begin{description}
 \item[btkSuperResolution] To be documented. 

\end{description}

\subsection{Anatomical segmentation}
\label{subsec:ana_seg}

\begin{description}
 \item[btkTissueSegmentation] This program allows to obtain :
        \begin{itemize}
         \item A segmentation of the brain which separate pericerebral LCR and ventricules,
         \item A segmentation of the cortex inside of a region of interest defined from the border between brain and pericerebral LCR,
        \end{itemize}
        as described in~\cite{caldairou_segmentation_2011}.
        
        Usage: \texttt{btkTissueSegmentation -i greyImage -s intracranianVolume -l brainstemSegmentation -l cerebellumSegmentation -o brainSegmentation -o cortexSegmentation}
\end{description}

\begin{description}
 \item[btkLabelPropagation] This program applies a patch-based label propagation algorithm for segmentation~\cite{rousseau_supervised_2011}. As a supervised method, it takes as input a textbook containing several anatomical images and the corresponding segmentation maps.
\end{description}


\subsection{Reconstruction of DW sequences \cite{oubel_reconstruction_2010}}
\label{subsec:diff_rec}
The reconstruction of diffusion-weighted (DW) sequences aims at
obtaining a sequence corrected for fetal moving and eddy-current distortions.
This can be performed in BTK by using the two following applications. 
\begin{description}
\item[btkGroupwiseS2SDistortionCorrection] It performs a groupwise
slice-by-slice registration of the image components of the sequence.

Minimal usage: \texttt{btkGroupwiseS2SDistortionCorrection -i input -o
output -t transform-folder}.

\begin{itemize}
 \item[-i] input sequence.
 \item[-o] output sequence.
 \item[-t] folder to save the transformation files
\end{itemize}

The slice-by-slice transform for a given DW image is saved as a set of $N$
transforms in ITK format, with $N$ the number of slices in the image.

NOTE: For slice registration, 20\% of the samples are used for computing the
image metric. As the region of interest of the slice can be small, this number
of samples might be insufficient to compute the metric accurately. However,
this percent of samples has been sufficient for the tested sequences. 

\item[btkRBFInterpolationS2S] It performs an interpolation of scattered data
generated from the application of slice-by-slice transforms. To this end,
radial basis functions are used. By default, the output has isotropic
voxels of size equal to the in-plane resolution of the input.

Minimal usage: \texttt{btkRBFInterpolationS2S -i input -m mask.nii -o output
-t transformation-folder}.

\begin{itemize}
 \item[-i] input sequence
 \item[-m] mask for the B0 image
 \item[-o] output sequence 
 \item[-t] folder with the transformations generated by
\texttt{btkGroupwiseS2SDistortionCorrection}
\end{itemize}

\end{description}


\subsection{Tractography \cite{pontabry_probabilistic_2011}}
\label{subsec:tracto}

** TO BE MODIFIED ** : THIS SECTION CORRESPONDS TO THE FOLLOWING PROGRAMS: btkODFParticleFilterTractography, btkODFStreamlineTractography, btkTensorParticleFilterTractography, btkTensorStreamlineTractography, btkTractography.

    \subsubsection*{Standard usage}
        Suppose you want to perform a tractography on a diffusion weighted MRI 
dataset. You should have a dwi image, the corresponding gradient vectors'
coordinates, a mask of the brain white matter and a label image of the seeds.
Assume this data is stored in files named repsectively for instance
\texttt{data.nii.gz}, \texttt{data.bvec}, \texttt{mask.nii.gz} and
\texttt{seeds.nii.gz}. The tractography is accomplished by the command below.
            \begin{quote}
                \texttt{btkTractography -d data.nii.gz -m mask.nii.gz -l seeds.nii.gz}
            \end{quote}
        When the program terminates its task, the probability connection map and
        the fibers estimation are saved in files respectively named
\texttt{map.nii.gz} and \texttt{fibers.vtk}. The connection map is a volume
image of probability intensities (\texttt{i.e.} intensities between 0 and 1)
with the same origin, orientation and spacing as the diffusion weighted image.
The fibers are polygonal data of VTK library in world coordinates. The standard
pipeline of the program is shown in
Fig.~\ref{btkTractography-fig:standard-pipeline}.
            \begin{figure}
                \centering
                \includegraphics[width=0.6\textwidth]{btkTractographyPipeline}
                \caption{Standard pipeline of the btkTractography program.}
                \label{btkTractography-fig:standard-pipeline}
            \end{figure}

        The file named \texttt{seeds.nii.gz} is a label map which is used to 
        generate seeds for the algorithm. The spacing in millimeters between
seeds can be adjust with the option \texttt{-\hspace{0.1mm}-seed\_spacing}.

        By default, Right-Anterior-Superior (RAS) coordinate system is used to 
        ensure compatibility with Slicer3D. However, it can be forced to use
Left-Posterior-Superior (LPS) coordinate system by using option \texttt{--lps}
on command line.

        If the DWI sequence contains more than one baseline image, the program 
        takes the average of all baseline images. The baseline images can be
everywhere in the sequence. It should be recognized by null vector in
corresponding gradient's table.

    \subsubsection*{Advanced usage}
        In addition to standard arguments of \texttt{btkTractography} program, 
        there are some other parameters that let you to alter algorithm's
behaviour. These options can be classified into three groups : model's options,
constraints on trajectory and filter's options. The first group options allow
you to tweak the model (for more details about it, please refer
to~\cite{descoteaux_regularized_2007}). The second group options let you to
control the particle's trajectory. These options provide prior informations to
the algorithm. The last group options are dedicated to the particle filter
control.

        Since the default parameters values may work in the most of cases, they 
        are optional. A list is of optional features is avaible by using the
command
            \begin{quote}
                \texttt{btkTractography -\hspace{0.1mm}-help} \hspace{0.5mm} or 
                \hspace{0.5mm} \texttt{btkTractography -h}
            \end{quote}
        and program's arguments are much more described below.


    \subsubsection*{Model's order}
        The model's order (i.e. the spherical harmonics' order) can be specified
        by the option
            \begin{quote}
                \texttt{-\hspace{0.1mm}-model\_order <order>} \enspace ,
            \end{quote}
        for \texttt{order}$\;\in\{2,4,6,8\}$. The default value is 4. For more 
        details, please refer to~\cite{descoteaux_regularized_2007}.

    \subsubsection*{Model's regularization}
        A Laplace-Beltrami regularization coefficient is used to assume a better
        estimation of the model. This coefficient can by manually modified by
the option
            \begin{quote}
                \texttt{-\hspace{0.1mm}-model\_regularization <coefficient>} \enspace ,
            \end{quote}
        for \texttt{coefficient}$\;\in\mathbb{R}$. The default value is set as 
        0.006. For more details, please refer
to~\cite{descoteaux_regularized_2007}.

    \subsubsection*{Displacement step size}
        The displacement step size of a moving particle can ben adjusted as you 
        want by using the option
            \begin{quote}
                \texttt{-\hspace{0.1mm}-step\_size <length>} \enspace ,
            \end{quote}
        where \texttt{length}$\;\in\mathbb{R}_+^*$. Note that this option is 
        expressed in~\texttt{mm}. The default value is fixed at 0.5~\texttt{mm}.
        By setting a big step size, the particles will move quickly. So the
biger is the step, the faster the algorithm will finish, but as shown by
Fig.~\ref{tracto-fig:stepSize}, some informations may be missed and the
particle's trajectories may overshoot the ground truth, resulting in a bad
estimation.

        \begin{figure}
            \centering
            \includegraphics[height=0.1\textheight]{stepSize}
            \caption{Effect of the step size option on a particle's trajectory. 
            With a large step size (right), the particle may overshoot the
trajectory of the ground truth.}
            \label{tracto-fig:stepSize}
        \end{figure}


    \subsubsection*{Angular threshold}
        An angular threshold prevent a particle to return back. This option has 
        to be expressed in radian and can bet set by
            \begin{quote}
                \texttt{-\hspace{0.1mm}-angular\_threshold <angle>} \enspace ,
            \end{quote}
        where \texttt{angle}$\;\in]0,2\pi[$. The default value is set as a 
        $\tfrac{\pi}{3}$ angle. As illustrated in two dimensions in
Fig.~\ref{tracto-fig:angleThreshold}, an angle threshold is used to define an
allowed area for successive sampled directions. This can be seen as a global
curvature parameters on trajectories. A small angle defines trajectories with a
small curvature. This is a prior information on ground truth trajectory.

        \begin{figure}
            \centering
            \includegraphics[height=0.1\textheight]{angleThreshold}
            \caption{An angle threshold allows the algorithm to sample
successive direction only in the cone defined by this angle. This
illustration show the principle in two dimensions.}
            \label{tracto-fig:angleThreshold}
        \end{figure}


    \subsubsection*{Rigidity}
        The rigidity option controls how much you want the particles to have 
        straight trajectory. You can adjust it by
            \begin{quote}
                \texttt{-\hspace{0.1mm}-curve\_constraint <rigidity>} \enspace ,
            \end{quote}
        where \texttt{rigidity}$\;\in\mathbb{R}_+^*$. The default value is
fixed at 30. This value correspond to a concentration parameter of a von
Mises-Fisher density probability used in the prior density of the system. As
Fig.~\ref{tracto-fig:concentration} illustrates locally in two dimensions, a
high value leads to a straight trajectory.

        \begin{figure}
            \centering
            \includegraphics[height=0.1\textheight]{concentration}
            \caption{Local effect of rigidity parameter on a particle's
trajectory. This parameter helps to ``attract'' the current
displacement vector in the direction of the previous displacement vector of a
particle. It correspond to a concentration paramter of a von Mise-Fisher density
probability used in the prior density of the system. For instance, a rigidity of
0 leads to an equiprobable distribution, whereas a rigidty tending to infinity
leads to a distribution focused on a point.}
            \label{tracto-fig:concentration}
        \end{figure}


    \subsubsection*{Number of particles}
        The number of particles in the system is set by the option
            \begin{quote}
                \texttt{-\hspace{0.1mm}-number\_of\_particles <number>} \enspace ,
            \end{quote}
        where \texttt{number}$\;\in\mathbb{N}^*$. By default, the algorithm will
        use 1000 particles. A poor number of particles leads to a short
computation time and a poor estimation. A large number of particles leads to a
long computation time and a good estimation. In general, the default number of
particles is a good compromise between computation time and estimation.


    \subsubsection*{Resampling threshold}
        This option modify the resampling threshold of the system. When the
number of effective particles in the system falls below this resampling
threshold, the particles are resampled according a multinomial resampling. It
can be adjust by
            \begin{quote}
                \texttt{-\hspace{0.1mm}-resampling\_threshold <percent>} \enspace ,
            \end{quote}
        where \texttt{percent}$\;\in[0,1]$ is the percent of minimal effective 
        particles in the system. A low threshold value will result in an
inefficient algorithm because the particles with low weight are not are not
often eliminated. Conversely, a high threshold value leads to a bad estimation
because the search space will not be explored enough.


\subsection{Atlas construction}
\label{subsec:atlas}

    First, the data script \emph{Scripts/btkAtlasData.py} should be copied in a directory and filled according to the dataset and the algorithms' options. Then the directory where the data script is have to be added in the python path environnement variable. For instance, in a terminal, the following command add the current directory in the python path environnement variable:
        \begin{quote}
            \texttt{export PYTHONPATH = \$PYTHONPATH:`pwd`} \enspace .
        \end{quote}
    Finaly, the atlas construction can be achieved by calling directly the following python scripts.

    \begin{description}
        \item[btkPrepareAtlasData] This optional script will split the tissue label map (named \emph{patient-name\_Tissues.nii.gz}) into separate tissue probability maps. Tissue name and label are controlled by setting up the script \emph{Scripts/btkAtlasData.py}.

        Usage: \texttt{btkPrepareAtlasData.py}

        \item[btkCreateTemplate.py] This script will use the informations contained in the data script to produce a template normalization as output.

        Usage: \texttt{btkCreateTemplate.py}

        \item[btkCreateLongitudinalAtlas.py] This script will use the informations contained in the data script and the output of the script btkCreateTemplate.py to produce a longitudinal atlas over gestionnal ages (in weeks) as output. So, the script btkCreateTemplate.py must be executed before using this script.

        Usage: \texttt{btkCreateLongitudinalAtlas.py}
    \end{description}

\subsection{Mask Extraction}
\label{subsec:Mask}

Suppose you want to extract automicaly masks of your images. First of all you should have some Atlas of foetal brain for different ages (in week).
In Addition you should know age of every image you want to process.
The pipeline will registrate the corresponding age template with the current image, finaly you will have a new template succefully registrate on you image and you can use it as a mask.
The mask extraction can be achieved by calling directly the first following python script.
    \begin{description}
        \item[btkMaskExtraction.py] This script will contain all your images, you must edit it ! It contain examples. This script is the only one you should execute, it will automaticaly search and execute the second one.

        Usage: \texttt{btkMaskExtraction.py}

        \item[btkMaskExtractionProcess.py] This script will process the pipeline, you must edit the images\_directory and template\_directory. Note that your image directory should respect a hierarchy (written in the script).

        Usage: Should be run by btkMaskExtraction.py or for advance user you can call like this : \texttt{btkMaskExtractionProcess.py subject exam age image01 image02 ...}
    \end{description}

\subsection{Fiber tracts Clustering}
\label{subsec:clustering}

Fiber tracts clustering is used to map the well-known fiber bundles of white matter.
This can be performed using the following applications:

\begin{description}
        \item[btkProbabilisticSegmentationMapBasedClustering] As supervised method, this program takes as input a probabilistic segmentation MAP of brain tissue which is an 4D image in \href{http://nifti.nimh.nih.gov/nifti-1}{Nifti} format.\\

	Usage: \texttt{btkProbabilisticSegmentationMapBasedClustering -b fiber\_tractography.vtk -p 4D\_prob\_segmentation\_map.nii.gz -o fiber\_clustering.vtk}\\
 
	Fig.\ref{clustering1-fig} shows an example of clustering results obtained using the method above.

	\begin{figure}[h]
	\centering
        \includegraphics[width=4cm]{Tarctography1-Left-View}
        \includegraphics[width=4cm]{Tarctography1-Anterior-View}
        \includegraphics[width=4cm]{Tarctography1-Interior-View}

        \includegraphics[width=4cm]{Clustering1-Left-View}
        \includegraphics[width=4cm]{Clustering1-Anterior-View}
        \includegraphics[width=4cm]{Clustering1-Interior-View}

        \caption{An example of fiber tracts clustering in the whole brain using \texttt{btkProbabilisticSegmentationMapBasedClustering} method.
        {\em The fibers from the tractography process and final clustering fiber bundles are shown in the first and second row, respectively. Three viewing angles of 3D depictions of fibers are shown (from left to right): left lateral view, anferior view and interior view. }}
        \label{clustering1-fig}
        \end{figure}

	\item[btkDistanceFibersKMeansApproximationClustering] As unsupervised method, this program makes it possible to cluster the fibers according to their anatomical regions using a distance metric based on the similarity between fibers.\\

	Usage: \texttt{btkDistanceFibersKMeansApproximationClustering -b fiber\_tractography.vtk -d distance\_measure -c number\_of\_clusters -o fiber\_clustering.vtk} \\

	The full list of optional parameters of this method can be obtained by:\\ 
        \texttt{btkDistanceFibersKMeansApproximationClustering --help}

	Fig.\ref{clustering2-fig} shows an example of clustering results in the corpus callosum region obtained using the method above with the following input parameters: \texttt{-d 10 -c 7}.

	\begin{figure}[h]
	\centering
        \includegraphics[width=4cm]{Corpus_Callosum-view2}
        \includegraphics[width=4cm]{Tractography-CC-view2}
        \includegraphics[width=4cm]{Clustering2-CC-view2}
        \caption{An example of fiber tracts clustering in the corpus callosum using \texttt{btkProbabilisticSegmentationMapBasedClustering} method.
        {\em The region of interest on the corpus callosum, fibers from the tractography process and final clustering fiber bundles are shown from left to right, respectively. The fibers are clustered according to anatomical regions as proposed by \href{brain.oxfordjournals.org/content/112/3/799}{Witelson}.}}
        \label{clustering2-fig}
        \end{figure}

\end{description}

\underline{NOTE}: The input and output data of these two applications are in \href{www.vtk.org/VTK/img/file-formats.pdf}{vtk} format.
